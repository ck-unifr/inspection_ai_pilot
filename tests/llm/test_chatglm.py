from dotenv import load_dotenv
from langchain_community.chat_models import ChatZhipuAI


def test():
    # 1. åŠ è½½ .env
    load_dotenv()

    # 2. åˆå§‹åŒ–æ¨¡å‹
    # æ³¨æ„ï¼šé€šå¸¸ API è¿™é‡Œçš„åå­—æ˜¯å°å†™çš„ 'glm-4v-flash'
    # å¦‚æœå®˜æ–¹æ˜ç¡®ç»™ä½ çš„ model code æ˜¯ 'glm-4.6v-flash'ï¼Œè¯·ç›´æ¥æ›¿æ¢ä¸‹é¢çš„å­—ç¬¦ä¸²
    llm = ChatZhipuAI(model="glm-4v-flash", temperature=0.5)

    # 3. è°ƒç”¨
    try:
        response = llm.invoke("ä»‹ç»ä¸€ä¸‹GLM-4V-Flashè¿™ä¸ªæ¨¡å‹æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ")
        print(response.content)
    except Exception as e:
        print(f"è°ƒç”¨å¤±è´¥: {e}")


if __name__ == "__main__":
    test()
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
